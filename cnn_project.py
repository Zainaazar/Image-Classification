# -*- coding: utf-8 -*-
"""CNN_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1id3hV7iOdV_XqwUHcG93kK-j0QDiJIWM

#CNN Project Using ResNet50, And Inception_v3 Pre-Trained Models On Intel Image Classification
From Kaggle

importing libraries
"""

import tensorflow as tf

from tensorflow import keras

from tensorflow.keras import layers, models, utils, callbacks, applications, optimizers, Input, Model

from sklearn.metrics import confusion_matrix

import matplotlib.pyplot as plt

import numpy as np

import itertools

import kagglehub

import os

from PIL import Image

"""Download dataset"""

path = kagglehub.dataset_download("puneet6060/intel-image-classification")
print("Dataset downloaded to:", path)

"""*Dataset* loading"""

# Correct paths to training & test folders
train_dir = os.path.join(path, "seg_train/seg_train")
val_dir   = os.path.join(path, "seg_test/seg_test")

# Load datasets
train_ds = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    image_size=(224,224),
    batch_size=32
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    val_dir,
    image_size=(224,224),
    batch_size=32
)

print("Train classes:", train_ds.class_names)
print("Validation classes:", val_ds.class_names)

"""Normalize images, Prefetch for performance"""

normalization_layer = layers.Rescaling(1./255)
train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)).prefetch(tf.data.AUTOTUNE)
val_ds   = val_ds.map(lambda x, y: (normalization_layer(x), y)).prefetch(tf.data.AUTOTUNE)

"""Data augmentation"""

data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
])

"""Input layer"""

input_tensor = keras.Input(shape=(224,224,3))

"""Apply augmentation"""

x = data_augmentation(input_tensor)

"""Load ResNet50 base model, Freeze most layers"""

resnet_model = applications.ResNet50(
    weights='imagenet',
    include_top=False,
    input_tensor=(x)
)


for layer in resnet_model.layers[:-4]:
    layer.trainable = False

resnet_out = layers.GlobalAveragePooling2D()(resnet_model.output)

"""Inception"""

inception_model = applications.InceptionV3(
    weights='imagenet',
    include_top=False,
    input_tensor=x
)
for layer in inception_model.layers[:-4]:
    layer.trainable = False
inception_out = layers.GlobalAveragePooling2D()(inception_model.output)

"""Combine features"""

combined_features = layers.Concatenate()([resnet_out, inception_out])

"""Classifier"""

dense = [layers.Dense(625, activation='relu')(combined_features),
         layers.Dropout(0.3)]
output = layers.Dense(6, activation='softmax')(combined_features)

"""Build model"""

model = Model(inputs=input_tensor, outputs=output)

"""compile"""

model.compile(
    optimizer=optimizers.Adam(learning_rate=1e-4),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

"""Callbacks"""

early_stop = callbacks.EarlyStopping(
    monitor="val_loss", patience=5, restore_best_weights=True
)

"""# Train"""

history = model.fit(
    train_ds,
    epochs=30,
    validation_data=val_ds,
    verbose=1,
    callbacks=[early_stop]
)

plt.plot(history.history["loss"], label="Training Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.title("Training vs Validation Loss")
plt.show()

"""Predictions

"""

y_pred_probs = model.predict(val_ds)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = np.concatenate([y for x, y in val_ds], axis=0)

"""Evaluate the model"""

loss, acc = model.evaluate(val_ds)
print('Accuracy =', acc)

"""# Confusion matrix"""

from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay

class_names = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']
cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)
plt.show()

"""Extract true labels safely

"""

print("Unique predictions:", np.unique(y_pred))
print("Unique true labels:", np.unique(y_true))

